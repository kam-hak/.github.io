# Nation-building in civil war; the penumbra of the adjacent possible; AI+Cambrian intelligence; agency+losing lower-leverage capacities

### When do we invest in nationalism (Alesina et al 2020) 

- @Alesina_2020_NationbuildingNationalismWars, in their discussion of nation-building, argue that nations invest in nationalism/ nation-building when it is no longer efficient to pay soldiers as mercenaries due to cost constraints (this is akin to Weinstein's account of relying on activist rebels). 
	- One way of doing this is *promising collective benefits in the future*, and signaling the ability to do this in the present. However, collective benefits are only attractive if you care about people in the groups receiving them. At large scale, for non-kin (tribal) networks, this must be a nation, i.e. an imagined community [@Anderson_1990_ImaginedCommunitiesReflections]. This 'positive national sentiment' approach allows for moral arguments for self-sacrificial actions for non-kin, see [@Boehm_2012_MoralOriginsEvolution].  
		- Additionally, nations need to *homogenize* preferences among the population (such as cultural preferences) so that public goods can meet a wide majority of preferences among the population. 
	- Another approach is 'negative national sentiment', in which a state invests in propaganda *against* the foreign nation. This is forging a homogenous preference *against* a foreign nation. This reduces the value of the outside option and unites the population against them. This is a *substitute* for public good provision (or maybe the public good is fighting against the enemy?).
	- A prediction of this model is that **states with low fiscal capacity** are more likely to pursue negative nationalism, since they cannot credibly commit to future public goods / collective benefits.
- Applying Alesina et al.'s insights to rebel groups, it seems that often groups attempt to use both negative and positive nation-building (e.g. @Wood_2003_InsurgentCollectiveAction describes rebel groups both using propaganda against the government and attempting to promise future benefits). 
	- An insight here, also, is that the requirement to coordinate with diverse ethnic rebel groups may forge *pluralistic nationalism*, as it attempts to homogenize preferences and promise collective benefits to a wider group (beyond ethnic group). This is applicable to Myanmar, in which the vast majority of groups are opposed to a common (non-ethnically defined) enemy.

### Knowledge and the 'penumbra' of the adjacent possible
- **Knowledge makes the world legible, but uncovers a new 'penumbra' of new possibilities for science to uncover**. Michael Nielsen has an incredible quote that when something previously illegible comes into view, it creates a 'penumbra' of new possibilities. This presents a puzzle for why the pace of scientific discover has slowed. It should *not* be the case that 'low-hanging fruit' has been grasped. Instead, each discovery should generate a new penumbra of possibilities for applying the new knowledge to new problems and opportunities which come into view.
	- This sense of legibility is closer to grokking than Scott's notion of high-modernism (though, clearly related). 
	- This 'penumbra' is actually the Adjacent Possible, though Nielsen did not use these words. The 'adjacent possible' is a concept from the complexity scientist Stuart Kauffman, expanded on my many others (e.g. [iterative adjacent possible](https://medium.com/@komorama/the-iterative-adjacent-possible-af3e7038357d)).
	- The adjacent possible is a relatively simple concept. Complex systems evolve. However, *from any specific board state* very few of the ≈infinite many possible states are feasibly accessible. The reasonably *possible* moves from the perspective of a specific board state (moment in the game) is your adjacent possible. These are always iterative (each move opens new one, assuming you don't lose). 
		- *The adjacent possible is a kind of shadow future, hovering on the edges of the present state of things, a map of all the ways in which the present can reinvent itself.* - Steven Johnson
		- Theoretically, a baby could write a perfect essay by randomly scribbling on a page. While this is in the possibility set, it is not *adjacently* possible, it is functionally impossible, statistically. [See Jorge Louis Borges's Library of Babel for an excellent reflection on this].
	- The evolutions of the social/technological world is the same. We are all playing from a new 'board state' made up of all past actions by humanity, and all available technology/know-how. These provide us with what is (not) possible. However, we cannot directly perceive this. We are all guessing. Thus, people may attempt a revolution, thinking the time is ripe. Or seek to build flying cars, thinking humanity is finally ready for the leap. However, the 'further out' each of these attempts are from today, the more risky they are. The most 'pieces' you have to supply to make them a reality, pieces that do not yet exist.
- Alex Komoroske expands this by [arguing that we can iteratively](https://medium.com/@komorama/the-iterative-adjacent-possible-af3e7038357d) build towards 'moonshot' goals by pushing the adjacent possible towards them, but not quixotically attempting to achieve them in one swoop. Here, you iteratively take *moderately risky* steps, and work towards an ultimate goal in a step-wise fashion, assessing your adjacent possible at each step. This is fundamentally less risky, since you are directionally moving towards a macro-goal, but no one step is risky. This may be a longer route to your ultimate (moonshot) goal. However, while an investor may be willing to look at 'expected value' (extraordinary outcome, extraordinary risk). As an individual, binary win/lose outcomes are risky, as you cannot average them, or 'play many tickets'. You only get one. 
	- Komoroske asks why more people don't do this. He argues that a) people are used to certainty and this approach requires acknowledging risk and uncertainty. b) people want to *do things* (use their brawn) and commit, not adapt and be very logical about their adjacent possible (use their brain). Thus, they posit a vision and move towards it until they 'die'. The adjacent possible is a better way.


### When will AIs switch to "Cambrian" Intelligence?

- **[Are AIs are categorically different from human intelligence?](https://lareviewofbooks.org/article/how-to-raise-your-artificial-intelligence-a-conversation-with-alison-gopnik-and-melanie-mitchell/)**: Alison Gopnik and Melanie Mitchell discuss how LLMs (though, unclear whether this is AI-in-principle) differs from human intelligence.
	- **Everything AIs say is a hallucination (Melanie)**: This is because an AI doesn't actually have a mental model of what is 'true', it only has statistical associations unrelated from a conception of reality outside of data. This is true for even fictional realities! For instance, unicorns are a mental model that we can consider in a fictional 'reality'. Of course, AIs are quite good at interpolating between conceptions. 
		- For instance, it seems that AI can be prompted to imagine unicorns fencing with their horns. However, they are decomposing the notion of horse, horn, and magic (seemingly somewhat bland).
	- **LLMs currently do not 'run experiments' on the world to change their mental models; they 'run experiments' to optimize**: This is a subtle distinction, where AI models currently are optimization machines, but they are not seeking understanding *per se* outside of these optimization domains. 
		- **Intelligence occurred in the 'Cambrian explosion'**, which is when organisms got 'actuators and sensors'. These allowed for coordination between sensing and acting. Because they have sensors and actuators for the *real world*, their mental models were conceptions of truth, rather than optimization according to an artificial constraint. [NOTE: it seems like the real differentiation is what optimization is determined by -- for organism intelligence, the optimization scope was defined by physical laws which were 'true'. For AI thus far, this has largely been determined by AI researchers who provide an artificially constrained maximization goal and tool set. A deeper problem seems to be AI's inability to ask self-directed questions without relying on some deterministic randomness seed. This is a blurry boundary to differentiate from humans.]
		- **There is work to move AI towards seeking truth**, according to Gopnik, this may be a route towards human-like intelligence. A core challenge is the ability to imagine counterfactuals in complex ways, especially imagining counterfactuals in social settings (how would X person with Y characteristics react to action Z).
	- **Human caregiving as alignment**: a fascinating reframing is that a core function of child-rearing is to 'align' the next generation towards values that are pro-human and pro-social. 


### Increasing requires giving up lower-leverage capabilities

- There is a large concern over the diminishment of human capabilities as a result of AI. This is especially true for human's ability to [write well](https://paulgraham.com/writes.html), [to code](https://www.nytimes.com/2024/11/24/business/computer-coding-boot-camps.html), and to think through problems. These concerns are legitimate. However, they overlook the possibility of transferring human time and cognition to 'higher-leverage' activities. If this occurs (and there is no guarantee it will -- AI should be self-consciously designed for [augmentation](https://jods.mitpress.mit.edu/pub/issue3-case/release/6) rather than [automation](https://shapingwork.mit.edu/research/applying-ai-to-rebuild-middle-class-jobs/#:~:text=Autor's%20thesis%20is%20not%20a,also%20published%20in%20Noema%20Magazine.)). 
- Nonetheless, the broader lesson is that lower-leverage capacities *must be given up* to make room for higher ones. Lower-leverage capacities are those which, while useful, provide less agentic leverage relative to some other option. It is a near universal truth that switching to high-leverage capacities reduces your lower leverage capacities. This law is constrained by limited human resources (especially cognition and time). Below are illustrative examples:
	- Typing negatively impacted penmanship (less time to practice, lower leverage)
	- Google maps has diminished self-navigation, but now you can navigate ≈anywhere confidently.
	- Division of labor reduced most people's capacity to produce their own food and/or clothing (among a near-infinite variety of other micro-skills, such as foraging), in exchange, they used time to focus on a smaller set of  higher-leverage capacities. 
	- Using calculators dramatically lowered people's ability to do mental math and have an intuitive understanding of basic numbers (though... the dramatic increase in numeracy overall may mean that the average skill still went up)
	- A personal assistant dramatically lowers fine-grain control of social calendar and even the quality of communication between friends (who are now interfacing with an intermediary)
	- It seems very likely that AI, especially with respect to writing and coding, will diminish out capability to construct prose and/or code with virtuosity. At least, in the same respect that we do today.
		- **Analogy:** As typing and email (etc) radically reduced the cost of producing and transmitting words, the art of communication became far less virtuosic. Instead of beauty, efficiency and clarity became most prized. And, instead of laboring over a few letters (low leverage), we send thousand and, for many, tens of thousands of 'throw-away' communications a year (texts, emails, voice notes, etc.). 

### Trade-off between actions-per minute (APM) and precision

- **Increasing our APM in the world**: Actions per minute (APM) is a measure of skill in real-time video games, which is separate from either accuracy (ability to do exactly what you want to do, such as aim) or strategy (understanding what the highest percentage action is). Instead, APM is the ability to perform *different* actions quickly (with the rate measured as per minute). APM factors into games in two ways: 1) if you take more actions per minute, you are likely to outplay your opponent all-else equal. You can take actions across different parts of the game board (or map), and you can adjust your previous actions at a much faster rate as the game gives you feedback. 2) certain strategies are APM dependent. Some strategies requires you to 'overwhelm' your opponent by attacking them at 3 or 4 places at once. Then, tactically retreating in the places where they defend. The notion is that, if you have faster APM, you will be able to both retreat and attack on multiple angles quickly, and the opponent will be unable to correctly allocate his/her defenses at the same pace -- thus allowing you to deal damaged at the undefended places, while retreating to take minimal damage in the others. Other examples are the need to input a number of actions extremely quickly (e.g. spells or manipulating your units technically) which are not automatic.
	- Increasing your APM in the world is analogous. You need to give up perfection to increase your APM, but make sure you don't lose too much fidelity. 
	- **Giving up accuracy/perfection for higher-APM is usually a good trade-off, with diminishing returns** higher APM players give up some accuracy for higher APM. There is always a trade-off, and giving up some is an excellent idea. However, at extremes, the highest possible APM is just 'spam clicking' a single spot, which is obviously useless. The alternative, extreme precision, is doing 10 actions per minute, each of which are precise to the pixel.
	- **Deliberative practice**: Precision and APM are are in tension, and there is a maximization point for each (which may differ by person and by task). However, deliberate practice for each is separable. One can practice precision quite slowly, or practice very high APM. The 'feel' of both needs to be internalized into a tacit capacity (know-how). For instance, when playing piano, you may practice playing very easy songs extremely fast, to accustom your fingers to moving very rapidly. However, you are playing very easy songs to reduce your need for complex precision. Inversely, you may play a complex song very slowly, to 'teach' your fingers the movements before you play at high speed. 

### Misc.

- **Conversation with a public health researcher on PM2.5 and how much is unknown**:
	- PM2.5 is *any* particulate matter which is 2.5 micrometers ($\leq\text{0.0025mm}$). We don't know whether it matters what these particulates are made of (i.e. if it's a carbon particulate or other.).
	- The response function to PM2.5 is also unknown:
		- Is there a saturation point past which there is limited effects?
		- What is the relationship between acute and chronic exposure to PM2.5?
	- Wildfires between 2019-2022 create reliably exogenous changes in PM2.5, providing an excellent opportunity to understand its effect.
	- They've distributed filters, randomizing whether they are real or fake. Somehow this passed ethics approval!
- **Using Tmux (multiplex add-on for terminal) and tmux resurrect to save sessions**:
	- Tmux is an excellent addon to save  your terminal sessions (allowing you to work on multiple projects and return to saved states). However, it does not natively persist through shut-down. Tmux resurrect allows you to save your tmux sessions persistently and return to them later.

---