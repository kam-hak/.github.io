<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2024-12-03-nation-building-in-civil-war-the-penumbra-of-the-adjacent-possible-ai-cambrian-intelligence-agency-losing-lower-leverage-capacities</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../styles.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1
id="nation-building-in-civil-war-the-penumbra-of-the-adjacent-possible-aicambrian-intelligence-agencylosing-lower-leverage-capacities">Nation-building
in civil war; the penumbra of the adjacent possible; AI+Cambrian
intelligence; agency+losing lower-leverage capacities</h1>
<h3 id="when-do-we-invest-in-nationalism-alesina-et-al-2020">When do we
invest in nationalism (Alesina et al 2020)</h3>
<ul>
<li><span class="citation"
data-cites="Alesina_2020_NationbuildingNationalismWars">Alesina, Reich,
and Riboni (2020)</span>, in their discussion of nation-building, argue
that nations invest in nationalism/ nation-building when it is no longer
efficient to pay soldiers as mercenaries due to cost constraints (this
is akin to Weinstein’s account of relying on activist rebels).
<ul>
<li>One way of doing this is <em>promising collective benefits in the
future</em>, and signaling the ability to do this in the present.
However, collective benefits are only attractive if you care about
people in the groups receiving them. At large scale, for non-kin
(tribal) networks, this must be a nation, i.e. an imagined community
<span class="citation"
data-cites="Anderson_1990_ImaginedCommunitiesReflections">(<strong>Anderson_1990_ImaginedCommunitiesReflections?</strong>)</span>.
This ‘positive national sentiment’ approach allows for moral arguments
for self-sacrificial actions for non-kin, see <span class="citation"
data-cites="Boehm_2012_MoralOriginsEvolution">(Boehm 2012)</span>.
<ul>
<li>Additionally, nations need to <em>homogenize</em> preferences among
the population (such as cultural preferences) so that public goods can
meet a wide majority of preferences among the population.</li>
</ul></li>
<li>Another approach is ‘negative national sentiment’, in which a state
invests in propaganda <em>against</em> the foreign nation. This is
forging a homogenous preference <em>against</em> a foreign nation. This
reduces the value of the outside option and unites the population
against them. This is a <em>substitute</em> for public good provision
(or maybe the public good is fighting against the enemy?).</li>
<li>A prediction of this model is that <strong>states with low fiscal
capacity</strong> are more likely to pursue negative nationalism, since
they cannot credibly commit to future public goods / collective
benefits.</li>
</ul></li>
<li>Applying Alesina et al.’s insights to rebel groups, it seems that
often groups attempt to use both negative and positive nation-building
(e.g. <span class="citation"
data-cites="Wood_2003_InsurgentCollectiveAction">Wood (2003)</span>
describes rebel groups both using propaganda against the government and
attempting to promise future benefits).
<ul>
<li>An insight here, also, is that the requirement to coordinate with
diverse ethnic rebel groups may forge <em>pluralistic nationalism</em>,
as it attempts to homogenize preferences and promise collective benefits
to a wider group (beyond ethnic group). This is applicable to Myanmar,
in which the vast majority of groups are opposed to a common
(non-ethnically defined) enemy.</li>
</ul></li>
</ul>
<h3 id="knowledge-and-the-penumbra-of-the-adjacent-possible">Knowledge
and the ‘penumbra’ of the adjacent possible</h3>
<ul>
<li><strong>Knowledge makes the world legible, but uncovers a new
‘penumbra’ of new possibilities for science to uncover</strong>. Michael
Nielsen has an incredible quote that when something previously illegible
comes into view, it creates a ‘penumbra’ of new possibilities. This
presents a puzzle for why the pace of scientific discover has slowed. It
should <em>not</em> be the case that ‘low-hanging fruit’ has been
grasped. Instead, each discovery should generate a new penumbra of
possibilities for applying the new knowledge to new problems and
opportunities which come into view.
<ul>
<li>This sense of legibility is closer to grokking than Scott’s notion
of high-modernism (though, clearly related).</li>
<li>This ‘penumbra’ is actually the Adjacent Possible, though Nielsen
did not use these words. The ‘adjacent possible’ is a concept from the
complexity scientist Stuart Kauffman, expanded on my many others
(e.g. <a
href="https://medium.com/@komorama/the-iterative-adjacent-possible-af3e7038357d">iterative
adjacent possible</a>).</li>
<li>The adjacent possible is a relatively simple concept. Complex
systems evolve. However, <em>from any specific board state</em> very few
of the ≈infinite many possible states are feasibly accessible. The
reasonably <em>possible</em> moves from the perspective of a specific
board state (moment in the game) is your adjacent possible. These are
always iterative (each move opens new one, assuming you don’t lose).
<ul>
<li><em>The adjacent possible is a kind of shadow future, hovering on
the edges of the present state of things, a map of all the ways in which
the present can reinvent itself.</em> - Steven Johnson</li>
<li>Theoretically, a baby could write a perfect essay by randomly
scribbling on a page. While this is in the possibility set, it is not
<em>adjacently</em> possible, it is functionally impossible,
statistically. [See Jorge Louis Borges’s Library of Babel for an
excellent reflection on this].</li>
</ul></li>
<li>The evolutions of the social/technological world is the same. We are
all playing from a new ‘board state’ made up of all past actions by
humanity, and all available technology/know-how. These provide us with
what is (not) possible. However, we cannot directly perceive this. We
are all guessing. Thus, people may attempt a revolution, thinking the
time is ripe. Or seek to build flying cars, thinking humanity is finally
ready for the leap. However, the ‘further out’ each of these attempts
are from today, the more risky they are. The most ‘pieces’ you have to
supply to make them a reality, pieces that do not yet exist.</li>
</ul></li>
<li>Alex Komoroske expands this by <a
href="https://medium.com/@komorama/the-iterative-adjacent-possible-af3e7038357d">arguing
that we can iteratively</a> build towards ‘moonshot’ goals by pushing
the adjacent possible towards them, but not quixotically attempting to
achieve them in one swoop. Here, you iteratively take <em>moderately
risky</em> steps, and work towards an ultimate goal in a step-wise
fashion, assessing your adjacent possible at each step. This is
fundamentally less risky, since you are directionally moving towards a
macro-goal, but no one step is risky. This may be a longer route to your
ultimate (moonshot) goal. However, while an investor may be willing to
look at ‘expected value’ (extraordinary outcome, extraordinary risk). As
an individual, binary win/lose outcomes are risky, as you cannot average
them, or ‘play many tickets’. You only get one.
<ul>
<li>Komoroske asks why more people don’t do this. He argues that a)
people are used to certainty and this approach requires acknowledging
risk and uncertainty. b) people want to <em>do things</em> (use their
brawn) and commit, not adapt and be very logical about their adjacent
possible (use their brain). Thus, they posit a vision and move towards
it until they ‘die’. The adjacent possible is a better way.</li>
</ul></li>
</ul>
<h3 id="when-will-ais-switch-to-cambrian-intelligence">When will AIs
switch to “Cambrian” Intelligence?</h3>
<ul>
<li><strong><a
href="https://lareviewofbooks.org/article/how-to-raise-your-artificial-intelligence-a-conversation-with-alison-gopnik-and-melanie-mitchell/">Are
AIs are categorically different from human intelligence?</a></strong>:
Alison Gopnik and Melanie Mitchell discuss how LLMs (though, unclear
whether this is AI-in-principle) differs from human intelligence.
<ul>
<li><strong>Everything AIs say is a hallucination (Melanie)</strong>:
This is because an AI doesn’t actually have a mental model of what is
‘true’, it only has statistical associations unrelated from a conception
of reality outside of data. This is true for even fictional realities!
For instance, unicorns are a mental model that we can consider in a
fictional ‘reality’. Of course, AIs are quite good at interpolating
between conceptions.
<ul>
<li>For instance, it seems that AI can be prompted to imagine unicorns
fencing with their horns. However, they are decomposing the notion of
horse, horn, and magic (seemingly somewhat bland).</li>
</ul></li>
<li><strong>LLMs currently do not ‘run experiments’ on the world to
change their mental models; they ‘run experiments’ to optimize</strong>:
This is a subtle distinction, where AI models currently are optimization
machines, but they are not seeking understanding <em>per se</em> outside
of these optimization domains.
<ul>
<li><strong>Intelligence occurred in the ‘Cambrian explosion’</strong>,
which is when organisms got ‘actuators and sensors’. These allowed for
coordination between sensing and acting. Because they have sensors and
actuators for the <em>real world</em>, their mental models were
conceptions of truth, rather than optimization according to an
artificial constraint. [NOTE: it seems like the real differentiation is
what optimization is determined by – for organism intelligence, the
optimization scope was defined by physical laws which were ‘true’. For
AI thus far, this has largely been determined by AI researchers who
provide an artificially constrained maximization goal and tool set. A
deeper problem seems to be AI’s inability to ask self-directed questions
without relying on some deterministic randomness seed. This is a blurry
boundary to differentiate from humans.]</li>
<li><strong>There is work to move AI towards seeking truth</strong>,
according to Gopnik, this may be a route towards human-like
intelligence. A core challenge is the ability to imagine counterfactuals
in complex ways, especially imagining counterfactuals in social settings
(how would X person with Y characteristics react to action Z).</li>
</ul></li>
<li><strong>Human caregiving as alignment</strong>: a fascinating
reframing is that a core function of child-rearing is to ‘align’ the
next generation towards values that are pro-human and pro-social.</li>
</ul></li>
</ul>
<h3
id="increasing-requires-giving-up-lower-leverage-capabilities">Increasing
requires giving up lower-leverage capabilities</h3>
<ul>
<li>There is a large concern over the diminishment of human capabilities
as a result of AI. This is especially true for human’s ability to <a
href="https://paulgraham.com/writes.html">write well</a>, <a
href="https://www.nytimes.com/2024/11/24/business/computer-coding-boot-camps.html">to
code</a>, and to think through problems. These concerns are legitimate.
However, they overlook the possibility of transferring human time and
cognition to ‘higher-leverage’ activities. If this occurs (and there is
no guarantee it will – AI should be self-consciously designed for <a
href="https://jods.mitpress.mit.edu/pub/issue3-case/release/6">augmentation</a>
rather than <a
href="https://shapingwork.mit.edu/research/applying-ai-to-rebuild-middle-class-jobs/#:~:text=Autor&#39;s%20thesis%20is%20not%20a,also%20published%20in%20Noema%20Magazine.">automation</a>).</li>
<li>Nonetheless, the broader lesson is that lower-leverage capacities
<em>must be given up</em> to make room for higher ones. Lower-leverage
capacities are those which, while useful, provide less agentic leverage
relative to some other option. It is a near universal truth that
switching to high-leverage capacities reduces your lower leverage
capacities. This law is constrained by limited human resources
(especially cognition and time). Below are illustrative examples:
<ul>
<li>Typing negatively impacted penmanship (less time to practice, lower
leverage)</li>
<li>Google maps has diminished self-navigation, but now you can navigate
≈anywhere confidently.</li>
<li>Division of labor reduced most people’s capacity to produce their
own food and/or clothing (among a near-infinite variety of other
micro-skills, such as foraging), in exchange, they used time to focus on
a smaller set of higher-leverage capacities.</li>
<li>Using calculators dramatically lowered people’s ability to do mental
math and have an intuitive understanding of basic numbers (though… the
dramatic increase in numeracy overall may mean that the average skill
still went up)</li>
<li>A personal assistant dramatically lowers fine-grain control of
social calendar and even the quality of communication between friends
(who are now interfacing with an intermediary)</li>
<li>It seems very likely that AI, especially with respect to writing and
coding, will diminish out capability to construct prose and/or code with
virtuosity. At least, in the same respect that we do today.
<ul>
<li><strong>Analogy:</strong> As typing and email (etc) radically
reduced the cost of producing and transmitting words, the art of
communication became far less virtuosic. Instead of beauty, efficiency
and clarity became most prized. And, instead of laboring over a few
letters (low leverage), we send thousand and, for many, tens of
thousands of ‘throw-away’ communications a year (texts, emails, voice
notes, etc.).</li>
</ul></li>
</ul></li>
</ul>
<h3
id="trade-off-between-actions-per-minute-apm-and-precision">Trade-off
between actions-per minute (APM) and precision</h3>
<ul>
<li><strong>Increasing our APM in the world</strong>: Actions per minute
(APM) is a measure of skill in real-time video games, which is separate
from either accuracy (ability to do exactly what you want to do, such as
aim) or strategy (understanding what the highest percentage action is).
Instead, APM is the ability to perform <em>different</em> actions
quickly (with the rate measured as per minute). APM factors into games
in two ways: 1) if you take more actions per minute, you are likely to
outplay your opponent all-else equal. You can take actions across
different parts of the game board (or map), and you can adjust your
previous actions at a much faster rate as the game gives you feedback.
2) certain strategies are APM dependent. Some strategies requires you to
‘overwhelm’ your opponent by attacking them at 3 or 4 places at once.
Then, tactically retreating in the places where they defend. The notion
is that, if you have faster APM, you will be able to both retreat and
attack on multiple angles quickly, and the opponent will be unable to
correctly allocate his/her defenses at the same pace – thus allowing you
to deal damaged at the undefended places, while retreating to take
minimal damage in the others. Other examples are the need to input a
number of actions extremely quickly (e.g. spells or manipulating your
units technically) which are not automatic.
<ul>
<li>Increasing your APM in the world is analogous. You need to give up
perfection to increase your APM, but make sure you don’t lose too much
fidelity.</li>
<li><strong>Giving up accuracy/perfection for higher-APM is usually a
good trade-off, with diminishing returns</strong> higher APM players
give up some accuracy for higher APM. There is always a trade-off, and
giving up some is an excellent idea. However, at extremes, the highest
possible APM is just ‘spam clicking’ a single spot, which is obviously
useless. The alternative, extreme precision, is doing 10 actions per
minute, each of which are precise to the pixel.</li>
<li><strong>Deliberative practice</strong>: Precision and APM are are in
tension, and there is a maximization point for each (which may differ by
person and by task). However, deliberate practice for each is separable.
One can practice precision quite slowly, or practice very high APM. The
‘feel’ of both needs to be internalized into a tacit capacity
(know-how). For instance, when playing piano, you may practice playing
very easy songs extremely fast, to accustom your fingers to moving very
rapidly. However, you are playing very easy songs to reduce your need
for complex precision. Inversely, you may play a complex song very
slowly, to ‘teach’ your fingers the movements before you play at high
speed.</li>
</ul></li>
</ul>
<h3 id="misc.">Misc.</h3>
<ul>
<li><strong>Conversation with a public health researcher on PM2.5 and
how much is unknown</strong>:
<ul>
<li>PM2.5 is <em>any</em> particulate matter which is 2.5 micrometers
(<span class="math inline">\(\leq\text{0.0025mm}\)</span>). We don’t
know whether it matters what these particulates are made of (i.e. if
it’s a carbon particulate or other.).</li>
<li>The response function to PM2.5 is also unknown:
<ul>
<li>Is there a saturation point past which there is limited
effects?</li>
<li>What is the relationship between acute and chronic exposure to
PM2.5?</li>
</ul></li>
<li>Wildfires between 2019-2022 create reliably exogenous changes in
PM2.5, providing an excellent opportunity to understand its effect.</li>
<li>They’ve distributed filters, randomizing whether they are real or
fake. Somehow this passed ethics approval!</li>
</ul></li>
<li><strong>Using Tmux (multiplex add-on for terminal) and tmux
resurrect to save sessions</strong>:
<ul>
<li>Tmux is an excellent addon to save your terminal sessions (allowing
you to work on multiple projects and return to saved states). However,
it does not natively persist through shut-down. Tmux resurrect allows
you to save your tmux sessions persistently and return to them
later.</li>
</ul></li>
</ul>
<hr />
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-Alesina_2020_NationbuildingNationalismWars"
class="csl-entry" role="listitem">
Alesina, Alberto, Bryony Reich, and Alessandro Riboni. 2020.
<span>“Nation-Building, Nationalism, and Wars.”</span> <em>Journal of
Economic Growth</em> 25 (4): 381–430. <a
href="https://doi.org/10.1007/s10887-020-09182-7">https://doi.org/10.1007/s10887-020-09182-7</a>.
</div>
<div id="ref-Boehm_2012_MoralOriginsEvolution" class="csl-entry"
role="listitem">
Boehm, Christopher. 2012. <em>Moral Origins: The Evolution of Virtue,
Altruism, and Shame</em>. New York, NY: Basic books.
</div>
<div id="ref-Wood_2003_InsurgentCollectiveAction" class="csl-entry"
role="listitem">
Wood, Elisabeth Jean. 2003. <em>Insurgent Collective Action and Civil
War in <span>El Salvador</span></em>. Cambridge Studies in Comparative
Politics. New York: Cambridge University Press.
</div>
</div>
</body>
</html>
